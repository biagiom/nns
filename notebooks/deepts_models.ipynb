{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating FLOPs requirementsc DeepTS for neural networks.\n",
    "**WORK IN PROGRESS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, RNN, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, Add, Flatten, SimpleRNNCell\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, TimeDistributed, LSTMCell\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's still here because DeepTS work in progress.\n",
    "class ModelSummary(object):\n",
    "    \"\"\"\n",
    "    FLOPs are computed for batch size = 1. Only Dense and Conv2D layers are taken into account.\n",
    "    FLOPs are forward FLOPs (inference) and should generally be used to compare models and not\n",
    "        estimating times.\n",
    "    Supported layers/wrappers:\n",
    "        Dense\n",
    "        Conv2D\n",
    "        Conv2DTranspose\n",
    "        RNNs/bidirectional RNNs with the following cells: SimpleRNNCell, LSTMCell and GRUCell\n",
    "        TimeDistributed with Dense, Conv2D and Conv2DTranspose\n",
    "\n",
    "    What if batch size > 1 and need backward/training FLOPs?\n",
    "       - For batch size N, multiple result by N.\n",
    "       - For backward FLOPs, multiply results by 2.\n",
    "       - For training FLOPs, multiply result by 3.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, verbose=False):\n",
    "        \"\"\"\n",
    "            TODO: What if user reuses layers with functional API?\n",
    "        \"\"\"\n",
    "        self.name = model.name\n",
    "        self.layers = []  # Per-layer statistics\n",
    "        self.gflops = 0.0  # Total model gFLOPs\n",
    "        self.nparams = model.count_params()  # Total model parameters\n",
    "        self.params_mb = 0  # Total size in MB for model parameters\n",
    "        self.verbose = verbose  # If true, print layers used in computations\n",
    "\n",
    "        for layer in model.layers:\n",
    "            repeat_count = 1\n",
    "            if isinstance(layer, TimeDistributed):\n",
    "                repeat_count = layer.input_shape[1]  # Batch, Length, FeatureDim1, FeatureDim2, ...\n",
    "                layer = layer.layer\n",
    "            if isinstance(layer, Dense):\n",
    "                self.compute_dense_layer_stats(layer, repeat_count)\n",
    "            elif isinstance(layer, Conv2D):\n",
    "                self.compute_conv2d_layer_stats(layer, repeat_count)\n",
    "            elif isinstance(layer, Conv2DTranspose):\n",
    "                self.compute_conv2dtranspose_layer_stats(layer, repeat_count)\n",
    "            elif isinstance(layer, (RNN, Bidirectional)):\n",
    "                self.compute_rnn_layer_stats(layer)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            layer['gflops'] /= 1e9\n",
    "            layer['params_mb'] = layer['nparams'] * 4 / (1024 * 1024)\n",
    "            self.gflops += layer['gflops']\n",
    "            self.params_mb += layer['params_mb']\n",
    "\n",
    "    def add_layer(self, **kwargs):\n",
    "        self.layers.append(kwargs)\n",
    "\n",
    "    def compute_rnn_layer_stats(self, layer):\n",
    "        num_steps = layer.input_shape[1]      # Number of time steps (sequence length)\n",
    "        input_size = layer.input_shape[2]     # Number of input features\n",
    "        output_size = layer.output_shape[-1]  # Number of output features\n",
    "        layer_params = layer.count_params()   # Number of layer parameters\n",
    "        layer_name = layer.name               # Name of a layer, will be qualified with cell type\n",
    "\n",
    "        repeat_count = 1                      # If bidirectional, this will be 2\n",
    "        if isinstance(layer, Bidirectional):\n",
    "            if layer.merge_mode == 'concat':\n",
    "                output_size = output_size // 2\n",
    "            elif layer.merge_mode is None:\n",
    "                raise NotImplementedError(\"Implement this!\")\n",
    "            repeat_count = 2\n",
    "            layer = layer.layer\n",
    "\n",
    "        # By default, number of later FLOPs is equal to RNN FLOPs\n",
    "        layer_flops = repeat_count * (num_steps * (input_size * output_size + output_size * output_size))\n",
    "        rnn_cell = None\n",
    "        if isinstance(layer.cell, SimpleRNNCell):\n",
    "            rnn_cell = 'SimpleRNN'\n",
    "        elif isinstance(layer.cell, LSTMCell):\n",
    "            rnn_cell = 'LSTM'\n",
    "            layer_flops *= 4\n",
    "        elif isinstance(layer.cell, GRUCell):\n",
    "            rnn_cell = 'GRU'\n",
    "            layer_flops *= 3\n",
    "\n",
    "        if rnn_cell:\n",
    "            self.add_layer(\n",
    "                name=\"{} ({})\".format(layer_name, rnn_cell),\n",
    "                gflops=layer_flops,\n",
    "                nparams=layer_params)\n",
    "        if self.verbose:\n",
    "            print(\"Found supported layer: type={}, num_steps={}, input_size={}, \"\n",
    "                  \"output_size={}.\".format(rnn_cell, num_steps, input_size, output_size))\n",
    "\n",
    "    def compute_dense_layer_stats(self, layer, repeat_count=1):\n",
    "        # Ignoring biases\n",
    "        if self.verbose:\n",
    "            print(\"Found supported layer: type=Dense, repeat_count={}.\".format(repeat_count))\n",
    "        self.add_layer(\n",
    "            name=layer.name,\n",
    "            gflops=repeat_count * (np.prod(layer.weights[0].shape)),\n",
    "            nparams=layer.count_params())\n",
    "\n",
    "    def compute_conv2d_layer_stats(self, layer, repeat_count=1):\n",
    "        \"\"\"\n",
    "            layer.weights[0].shape  :  Filter Shape [FilterDim, FilterDim, InChannels, OutChannels]\n",
    "            layer.output_shape      :  [Batch, SpatialDim, SpatialDim, OutChannels]\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"Found supported layer: type=Conv2D, repeat_count={}.\".format(repeat_count))\n",
    "        # Number of flops per one output feature\n",
    "        filter_flops = np.prod(layer.weights[0].shape)\n",
    "        self.add_layer(\n",
    "            name=layer.name,\n",
    "            gflops=repeat_count * (filter_flops * layer.output_shape[1] * layer.output_shape[2]),\n",
    "            nparams=layer.count_params())\n",
    "\n",
    "    def compute_conv2dtranspose_layer_stats(self, layer, repeat_count=1):    \n",
    "        \"\"\"\n",
    "            Double check this implementation. Consider this layer as Conv2D reversing forward/backward\n",
    "            passes.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"Found supported layer: type=Conv2DTranspose, repeat_count={}.\".format(repeat_count))\n",
    "        # Number of flops per one output feature for 'depth' column\n",
    "        filter_flops = np.prod(layer.weights[0].shape)\n",
    "        self.add_layer(\n",
    "            name=layer.name,\n",
    "            gflops=repeat_count * (filter_flops * layer.input_shape[1] * layer.input_shape[2]),\n",
    "            nparams=layer.count_params())\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"batch_size=1, forward_gflops={:.4f}, nparams={:,}\".format(self.gflops, self.nparams)\n",
    "\n",
    "    def summary(self):\n",
    "        df = pd.DataFrame(self.layers + [{'name': 'TOTAL', 'gflops': self.gflops, 'nparams': self.nparams,\n",
    "                                          'params_mb': self.params_mb}],\n",
    "                          columns=['name', 'gflops', 'nparams', 'params_mb'])\n",
    "        print(self.name)\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \"\"\" A base class for all NN models. \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def create(self):\n",
    "        \"\"\" This method must return an instance of `tensorflow.python.keras.models.Model`. \"\"\"\n",
    "        raise NotImplementedError('Implement me in a derived class.')\n",
    "\n",
    "    @staticmethod\n",
    "    def Dense(size, activation='relu', **kwargs):\n",
    "        return tf.keras.layers.Dense(size, activation=activation, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def Input(shape, name='input'):\n",
    "        return tf.keras.layers.Input(shape, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Anomaly Detect\n",
    "Example code for neural-network-based anomaly detection of time-series data (uses LSTM). Super simple and not particularly usefull ([repo](https://github.com/aurotripathy/lstm-anomaly-detect)).  \n",
    "1. Sequence length = 100\n",
    "2. Number of features = 1\n",
    "3. Batch size = 50\n",
    "4. Data is synthetic.\n",
    "\n",
    "Three LSTM layers (64, 256, 100). Input length is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model01(Model):\n",
    "    \"\"\" \n",
    "    Super simple and not particularly usefull:\n",
    "        https://github.com/aurotripathy/lstm-anomaly-detect\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__('Model01: LSTM anomaly detection')\n",
    "\n",
    "    def create(self):\n",
    "        return tf.keras.models.Sequential([\n",
    "            Model.Input((100,1)),\n",
    "            LSTM(64, return_sequences=True, name='lstm1'),\n",
    "            Dropout(0.2),\n",
    "            LSTM(256, return_sequences=True, name='lstm2'),\n",
    "            Dropout(0.2),\n",
    "            LSTM(100, return_sequences=False, name='lstm3'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='linear', name='output')\n",
    "        ], name=self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model01: LSTM anomaly detection\n",
      "           name        gflops  nparams  params_mb\n",
      "0  lstm1 (LSTM)  1.664000e-03    16896   0.064453\n",
      "1  lstm2 (LSTM)  3.276800e-02   328704   1.253906\n",
      "2  lstm3 (LSTM)  1.424000e-02   142800   0.544739\n",
      "3        output  1.000000e-07      101   0.000385\n",
      "4         TOTAL  4.867210e-02   488501   1.863483\n"
     ]
    }
   ],
   "source": [
    "with contextlib.redirect_stderr(None):\n",
    "    ModelSummary(Model01().create()).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Anomaly Detection\n",
    "A repository with various models (FCNN, LSTM and Conv) for detecting anomalies ([repo](https://github.com/chen0040/keras-anomaly-detection)).\n",
    " LSTM models are defined [here](https://github.com/chen0040/keras-anomaly-detection/blob/master/keras_anomaly_detection/library/recurrent.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model02(Model):\n",
    "    \"\"\" \n",
    "    https://github.com/chen0040/keras-anomaly-detection/blob/master/keras_anomaly_detection/library/recurrent.py#L7\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__('Model02: LSTM anomaly detection')\n",
    "\n",
    "    def create(self):\n",
    "        # Sequence length = 210, number of features = 1, batch size = ?\n",
    "        return tf.keras.models.Sequential([\n",
    "            Model.Input((210,1)),\n",
    "            LSTM(128, return_sequences=False, name='lstm1'),\n",
    "            Dense(128, activation='linear', name='output')\n",
    "        ], name=self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model02: LSTM anomaly detection\n",
      "           name    gflops  nparams  params_mb\n",
      "0  lstm1 (LSTM)  0.013870    66560   0.253906\n",
      "1        output  0.000016    16512   0.062988\n",
      "2         TOTAL  0.013886    83072   0.316895\n"
     ]
    }
   ],
   "source": [
    "with contextlib.redirect_stderr(None):\n",
    "    ModelSummary(Model02().create()).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model03(Model):\n",
    "    \"\"\" \n",
    "    https://github.com/chen0040/keras-anomaly-detection/blob/master/keras_anomaly_detection/library/recurrent.py#L218\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__('Model03: bidirectional LSTM anomaly detection')\n",
    "\n",
    "    def create(self):\n",
    "        # Sequence length = 210, number of features = 1, batch size = ?\n",
    "        return tf.keras.models.Sequential([e\n",
    "            Input(shape=(210,1)),\n",
    "            Bidirectional(LSTM(128, return_sequences=False), name='bLSTM'),\n",
    "            Dense(128, activation='linear', name='output')\n",
    "        ], name=self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model03: bidirectional LSTM anomaly detection\n",
      "           name    gflops  nparams  params_mb\n",
      "0  bLSTM (LSTM)  0.027740   133120   0.507812\n",
      "1        output  0.000033    32896   0.125488\n",
      "2         TOTAL  0.027773   166016   0.633301\n"
     ]
    }
   ],
   "source": [
    "with contextlib.redirect_stderr(None):\n",
    "    ModelSummary(Model03().create()).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MTSAnomalyDetection](https://github.com/jsonbruce/MTSAnomalyDetection)\n",
    " \n",
    "Multidimensional Time Series Anomaly Detection (MTSAD). Model is implemented [here](https://github.com/jsonbruce/MTSAnomalyDetection/blob/master/ensemblation/model.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model04(Model):\n",
    "    \"\"\" \n",
    "    https://github.com/chen0040/keras-anomaly-detection/blob/master/keras_anomaly_detection/library/recurrent.py#L218\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__('Model03: bidirectional LSTM anomaly detection')\n",
    "\n",
    "    def create(self):\n",
    "        # Sequence length = 210, number of features = 1, batch size = ?\n",
    "        return tf.keras.models.Sequential([\n",
    "            Model.Input((210,1)),\n",
    "            Bidirectional(LSTM(128, return_sequences=False), name='bLSTM'),\n",
    "            Dense(128, activation='linear', name='output')\n",
    "        ], name=self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model03: bidirectional LSTM anomaly detection\n",
      "           name    gflops  nparams  params_mb\n",
      "0  bLSTM (LSTM)  0.027740   133120   0.507812\n",
      "1        output  0.000033    32896   0.125488\n",
      "2         TOTAL  0.027773   166016   0.633301\n"
     ]
    }
   ],
   "source": [
    "with contextlib.redirect_stderr(None):\n",
    "    ModelSummary(Model04().create()).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
