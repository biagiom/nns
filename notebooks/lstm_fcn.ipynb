{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-FCN for time series classification\n",
    "\n",
    "Project on [GitHub](https://github.com/titu1994/LSTM-FCN), [paper](https://ieeexplore.ieee.org/document/8141873/). Models work OK for univariate time series.\n",
    "\n",
    "![LSTM FCN model](https://raw.githubusercontent.com/titu1994/LSTM-FCN/master/images/LSTM-FCN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath('')), 'python'))\n",
    "from nns.nns import ModelSummary, reset_keras, printable_dataframe, estimate\n",
    "from nns import dlbs_models as models\n",
    "\n",
    "from tensorflow.python.keras import layers, models, regularizers\n",
    "\n",
    "#import tensorflow as tf\n",
    "#import tensorflow.contrib.keras as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problems are defined here:\n",
    "# https://github.com/titu1994/LSTM-FCN/blob/master/utils/constants.py\n",
    "\n",
    "# Problem 118: http://www.timeseriesclassification.com/description.php?Dataset=PigCVP\n",
    "#     Train size: 104, test size: 208, length: 2000, num_classes: 52\n",
    "MAX_SEQUENCE_LENGTH = 2000    # 118\n",
    "NB_CLASSES =52                # 118\n",
    "NUM_CELLS = 128               # Largest value in `all_datasets_training.py`\n",
    "\n",
    "perf = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lstmfcn(max_sequence_length, nb_classes, num_cells=8):\n",
    "    ip = layers.Input(shape=(1, max_sequence_length))\n",
    "\n",
    "    x = layers.LSTM(num_cells)(ip)\n",
    "    x = layers.Dropout(0.8)(x)\n",
    "\n",
    "    y = layers.Permute((2, 1))(ip)\n",
    "    y = layers.Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "\n",
    "    y = layers.Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "\n",
    "    y = layers.Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "\n",
    "    y = layers.GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = layers.Concatenate()([x, y])\n",
    "\n",
    "    out = layers.Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(ip, out, name='LSTM-FCN')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0523 04:39:25.647135 140196554352384 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.LSTM object at 0x7f8172e482b0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer not recognized (type=<class 'tensorflow.python.keras.engine.input_layer.InputLayer'>, name=input_1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>out_shape</th>\n",
       "      <th>gFLOPs</th>\n",
       "      <th>num_params</th>\n",
       "      <th>num_activations</th>\n",
       "      <th>params_mem (MB)</th>\n",
       "      <th>activations_mem (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input</td>\n",
       "      <td>(1, 2000)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>permute</td>\n",
       "      <td>(2000, 1)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conv1d</td>\n",
       "      <td>(2000, 128)</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>1152</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>1.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_normalization_v1</td>\n",
       "      <td>(2000, 128)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>1.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>activation</td>\n",
       "      <td>(2000, 128)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conv1d_1</td>\n",
       "      <td>(2000, 256)</td>\n",
       "      <td>0.327680</td>\n",
       "      <td>164096</td>\n",
       "      <td>512000</td>\n",
       "      <td>0.656384</td>\n",
       "      <td>2.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>batch_normalization_v1_1</td>\n",
       "      <td>(2000, 256)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>512</td>\n",
       "      <td>512000</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>2.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>activation_1</td>\n",
       "      <td>(2000, 256)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>512000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conv1d_2</td>\n",
       "      <td>(2000, 128)</td>\n",
       "      <td>0.196608</td>\n",
       "      <td>98432</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.393728</td>\n",
       "      <td>1.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>batch_normalization_v1_2</td>\n",
       "      <td>(2000, 128)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>1.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lstm (LSTM)</td>\n",
       "      <td>(128,)</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>1090048</td>\n",
       "      <td>1792</td>\n",
       "      <td>4.360192</td>\n",
       "      <td>0.007168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>activation_2</td>\n",
       "      <td>(2000, 128)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dropout</td>\n",
       "      <td>(128,)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>global_average_pooling1d</td>\n",
       "      <td>(128,)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>concatenate</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dense</td>\n",
       "      <td>(52,)</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>13364</td>\n",
       "      <td>104</td>\n",
       "      <td>0.053456</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>(52,)</td>\n",
       "      <td>0.527439</td>\n",
       "      <td>1369140</td>\n",
       "      <td>3078408</td>\n",
       "      <td>5.476560</td>\n",
       "      <td>12.313632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name    out_shape    gFLOPs  num_params  \\\n",
       "0                      input    (1, 2000)  0.000000           0   \n",
       "1                    permute    (2000, 1)  0.000000           0   \n",
       "2                     conv1d  (2000, 128)  0.002048        1152   \n",
       "3     batch_normalization_v1  (2000, 128)  0.000000         256   \n",
       "4                 activation  (2000, 128)  0.000000           0   \n",
       "5                   conv1d_1  (2000, 256)  0.327680      164096   \n",
       "6   batch_normalization_v1_1  (2000, 256)  0.000000         512   \n",
       "7               activation_1  (2000, 256)  0.000000           0   \n",
       "8                   conv1d_2  (2000, 128)  0.196608       98432   \n",
       "9   batch_normalization_v1_2  (2000, 128)  0.000000         256   \n",
       "10               lstm (LSTM)       (128,)  0.001090     1090048   \n",
       "11              activation_2  (2000, 128)  0.000000           0   \n",
       "12                   dropout       (128,)  0.000000           0   \n",
       "13  global_average_pooling1d       (128,)  0.000000           0   \n",
       "14               concatenate       (256,)  0.000000           0   \n",
       "15                     dense        (52,)  0.000013       13364   \n",
       "16                     TOTAL        (52,)  0.527439     1369140   \n",
       "\n",
       "    num_activations  params_mem (MB)  activations_mem (MB)  \n",
       "0              2000         0.000000              0.008000  \n",
       "1              2000         0.000000              0.008000  \n",
       "2            256000         0.004608              1.024000  \n",
       "3            256000         0.001024              1.024000  \n",
       "4            256000         0.000000              1.024000  \n",
       "5            512000         0.656384              2.048000  \n",
       "6            512000         0.002048              2.048000  \n",
       "7            512000         0.000000              2.048000  \n",
       "8            256000         0.393728              1.024000  \n",
       "9            256000         0.001024              1.024000  \n",
       "10             1792         4.360192              0.007168  \n",
       "11           256000         0.000000              1.024000  \n",
       "12              128         0.000000              0.000512  \n",
       "13              128         0.000000              0.000512  \n",
       "14              256         0.000000              0.001024  \n",
       "15              104         0.053456              0.000416  \n",
       "16          3078408         5.476560             12.313632  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate(generate_lstmfcn(MAX_SEQUENCE_LENGTH, NB_CLASSES, NUM_CELLS), perf, perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Input shape</th>\n",
       "      <th>#Parameters</th>\n",
       "      <th>Model size (MB) FP32</th>\n",
       "      <th>GFLOPs (multiply-add)</th>\n",
       "      <th>Activation size (MB) FP32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM-FCN</td>\n",
       "      <td>inference</td>\n",
       "      <td>(1, 2000)</td>\n",
       "      <td>1369140</td>\n",
       "      <td>5.47656</td>\n",
       "      <td>0.527439</td>\n",
       "      <td>12.313632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM-FCN</td>\n",
       "      <td>training</td>\n",
       "      <td>(1, 2000)</td>\n",
       "      <td>1369140</td>\n",
       "      <td>5.47656</td>\n",
       "      <td>1.582317</td>\n",
       "      <td>24.627264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model      Phase Input shape  #Parameters  Model size (MB) FP32  \\\n",
       "0  LSTM-FCN  inference   (1, 2000)      1369140               5.47656   \n",
       "1  LSTM-FCN   training   (1, 2000)      1369140               5.47656   \n",
       "\n",
       "   GFLOPs (multiply-add)  Activation size (MB) FP32  \n",
       "0               0.527439                  12.313632  \n",
       "1               1.582317                  24.627264  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_oder = ['name', 'phase', 'input_shape', 'num_parameters', 'param_memory', 'flops', 'activation_memory']\n",
    "columns = {'name': 'Model', 'phase': 'Phase', 'input_shape': 'Input shape', 'num_parameters': '#Parameters',\n",
    "           'param_memory': 'Model size (MB) FP32', 'flops': 'GFLOPs (multiply-add)',\n",
    "           'activation_memory': 'Activation size (MB) FP32'}\n",
    "df = pd.DataFrame(perf, columns=column_oder)\n",
    "df.rename(columns=columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
